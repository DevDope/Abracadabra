{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevDope/Abracadabra/blob/main/End_Abracadabra_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og8AE6iwwyH0"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch==2.4.1\n",
        "!pip install chromadb\n",
        "!pip install tqdm\n",
        "!pip uninstall pydantic -y\n",
        "!pip install pydantic==1.10.9\n",
        "!pip install gradio==3.41.2\n",
        "!pip install farm-haystack[transformers] transformers torch\n",
        "!pip install -U httpx httpcore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import chromadb\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "chromadb_path = '/content/drive/My Drive/chroma_db'\n",
        "\n",
        "\n",
        "db = chromadb.PersistentClient(path=chromadb_path)\n",
        "\n",
        "\n",
        "chroma_collection = db.get_or_create_collection(\"music_recommendation\")\n",
        "\n",
        "collection = db.get_or_create_collection(\"music_recommendation\")\n",
        "print(f\"Colección 'music_recommendation' cargada: {chroma_collection}\")"
      ],
      "metadata": {
        "id": "Bqc_BjIU8OBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "login(token=\"your token here!\")\n"
      ],
      "metadata": {
        "id": "SbdJdsz8Bg01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from chromadb import PersistentClient\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from IPython.display import Markdown, display\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    raise ValueError(\"error\")\n"
      ],
      "metadata": {
        "id": "bJkYUK6hBtTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_content = \"\"\"\n",
        "version: \"1.0\"\n",
        "components:\n",
        "  - name: DocumentStore\n",
        "    type: InMemoryDocumentStore\n",
        "    params:\n",
        "      similarity: \"cosine\"\n",
        "\n",
        "  - name: Retriever\n",
        "    type: DensePassageRetriever\n",
        "    params:\n",
        "      document_store: DocumentStore\n",
        "      query_embedding_model: \"facebook/dpr-question_encoder-single-nq-base\"\n",
        "      passage_embedding_model: \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
        "      use_gpu: True\n",
        "\n",
        "  - name: PopularSongRetriever\n",
        "    type: EmbeddingRetriever\n",
        "    params:\n",
        "      document_store: DocumentStore\n",
        "      embedding_model: \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "      pooling_strategy: \"mean\"\n",
        "      use_gpu: True\n",
        "      top_k: 10\n",
        "\n",
        "pipelines:\n",
        "  - name: context_retrieval\n",
        "    nodes:\n",
        "      - name: Retriever\n",
        "        inputs: [Query]\n",
        "      - name: PopularSongRetriever\n",
        "        inputs: [Retriever]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "with open(\"/content/pipeline.yaml\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(yaml_content)\n",
        "\n",
        "print(\"Archivo 'pipeline.yaml' actualizado y creado con éxito.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PPzjvJRvl3w7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30abe239-3211-401b-ad66-8b6fa1f79f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo 'pipeline.yaml' actualizado y creado con éxito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from haystack.pipelines import Pipeline\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "from haystack.nodes import DensePassageRetriever\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True,\n",
        "    trust_remote_code=True\n",
        ").to(\"cuda\")\n",
        "\n",
        "\n",
        "pipeline = Pipeline.load_from_yaml(path=\"/content/pipeline.yaml\", pipeline_name=\"context_retrieval\")\n",
        "document_store = InMemoryDocumentStore()\n",
        "retriever = DensePassageRetriever(document_store=document_store)\n",
        "document_store.update_embeddings(retriever)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "song_history = set()\n",
        "\n",
        "GENRES = [\n",
        "    'hip-hop', 'pop', 'rap', 'rock', 'indie', 'folk', 'electronic', 'soul',\n",
        "    'classic rock', 'rnb', 'alternative', 'math rock', 'j-pop', 'country', 'indie rock',\n",
        "    'hip hop', 'alternative rock', 'metal', 'jazz', 'indie pop', 'reggae', 'punk',\n",
        "    'metalcore', 'post-hardcore', 'christian', 'worship', 'experimental', 'hard rock',\n",
        "    'punk rock', 'trap', 'pop punk', 'hardcore', 'progressive rock', 'dance', 'emo',\n",
        "    'new wave', 'acoustic', 'funk', 'blues', 'heavy metal', 'psychedelic', 'post-punk',\n",
        "    'soundtrack', 'cloud rap', 'lo-fi', 'progressive metal', 'dub', 'dancehall', 'dream pop',\n",
        "    'synthpop', 'comedy', 'death metal', 'thrash metal', 'alt-country', 'house', 'pop rock',\n",
        "    'psychedelic rock', 'ambient', 'grunge', 'shoegaze', 'industrial', 'black metal',\n",
        "    'screamo', 'emo rap', 'nu metal', 'garage rock', 'power metal', 'gospel', 'electropop',\n",
        "    'deathcore', 'chillout', 'grime', 'britpop', 'trip-hop', 'melodic death metal', 'dubstep',\n",
        "    'disco', 'doom metal', 'swing', 'lo-fi', 'k-pop', 'chillwave', 'trance', 'techno', 'house',\n",
        "    'drum and bass', 'electro', 'reggaeton', 'classical', 'latin'\n",
        "]\n",
        "EMOTIONS = [\"joy\", \"love\", \"calm\", \"mystic\", \"serene\",\"angry\",\"suprise\"]\n",
        "\n",
        "def extract_keywords_from_prompt(prompt, top_n=10):\n",
        "    vectorizer = CountVectorizer(max_features=top_n, stop_words='english')\n",
        "    X = vectorizer.fit_transform([prompt])\n",
        "    keywords = vectorizer.get_feature_names_out()\n",
        "    return keywords\n",
        "\n",
        "def extract_filters(prompt):\n",
        "    emotion_filter = [word for word in EMOTIONS if word in prompt.lower()]\n",
        "    genre_filter = [word for word in GENRES if word in prompt.lower()]\n",
        "    return {\"emotion\": emotion_filter, \"genre\": genre_filter}\n",
        "\n",
        "PROHIBITED_KEYWORDS = [\"violence\", \"explicit\", \"inappropriate_word1\", \"inappropriate_word2\"]\n",
        "\n",
        "def filter_prohibited_content(documents):\n",
        "    filtered_docs = []\n",
        "    for doc in documents:\n",
        "        title = doc.get('song', '').lower()\n",
        "        text = doc.get('text', '').lower()\n",
        "\n",
        "        if not any(keyword in title for keyword in PROHIBITED_KEYWORDS) and \\\n",
        "           not any(keyword in text for keyword in PROHIBITED_KEYWORDS):\n",
        "            filtered_docs.append(doc)\n",
        "    return filtered_docs\n",
        "\n",
        "def search_documents(query, genre_filter, top_k=50):\n",
        "    lyric_keywords = extract_keywords_from_prompt(query)\n",
        "\n",
        "    start_time = time.time()\n",
        "    results = pipeline.run(query=query, params={\"Retriever\": {\"top_k\": 100, \"filters\": {\"genre\": genre_filter}}})\n",
        "    popular_results = pipeline.run(query=query, params={\"PopularSongRetriever\": {\"top_k\": 100}})\n",
        "    end_time = time.time()\n",
        "    print(f\"Búsqueda de documentos completada en {end_time - start_time:.2f} segundos.\")\n",
        "\n",
        "    filtered_results = filter_prohibited_content(results['documents'])\n",
        "    unique_artists = set()\n",
        "    final_results = []\n",
        "\n",
        "    for doc in filtered_results:\n",
        "        title = doc['song'].lower()\n",
        "        text = doc['text'].lower()\n",
        "        artist = doc['artist'].lower()\n",
        "        song_genre = doc.get('genre', '').lower()\n",
        "\n",
        "        if genre_filter in song_genre and artist not in unique_artists:\n",
        "            title_match = any(keyword in title for keyword in lyric_keywords)\n",
        "            text_match = any(keyword in text for keyword in lyric_keywords)\n",
        "\n",
        "            if title_match:\n",
        "                final_results.append((doc, 2))\n",
        "                unique_artists.add(artist)\n",
        "            elif text_match:\n",
        "                final_results.append((doc, 1))\n",
        "                unique_artists.add(artist)\n",
        "\n",
        "    random.shuffle(popular_results['documents'])\n",
        "    for pos in [0, 2, 9]:\n",
        "        if pos < len(popular_results['documents']):\n",
        "            popular_doc = popular_results['documents'][pos]\n",
        "            artist = popular_doc['artist'].lower()\n",
        "            song_genre = popular_doc.get('genre', '').lower()\n",
        "            if artist not in unique_artists and genre_filter in song_genre:\n",
        "                final_results.insert(pos, (popular_doc, 3))\n",
        "                unique_artists.add(artist)\n",
        "\n",
        "    final_results.sort(key=lambda x: x[1], reverse=True)\n",
        "    random.shuffle(final_results)\n",
        "\n",
        "    return [doc[0].content for doc in final_results[:top_k]]\n",
        "\n",
        "def generate_response(prompt, retrieved_songs, max_new_tokens=800):\n",
        "    context = \"\\n\".join(\n",
        "        f\"{i+1}. '{song['title']}' by {song['artist']} - A {song.get('genre', 'genre')} song with a {song.get('emotion', 'emotion')} feel. \"\n",
        "        f\"Lyric snippet: \\\"{song['text'][:100]}...\\\"\"\n",
        "        for i, song in enumerate(retrieved_songs)\n",
        "    )\n",
        "\n",
        "    final_prompt = (\n",
        "        f\"{prompt}\\n\\n\"\n",
        "        f\"Here is a playlist that captures the ambiance you described, with popular and themed selections:\\n\\n\"\n",
        "        f\"{context}\\n\\n\"\n",
        "        f\"Playlist:\\n1.\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(final_prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response.strip()\n",
        "\n",
        "def clean_response(response):\n",
        "    lines = response.split(\"\\n\")\n",
        "    cleaned_lines = []\n",
        "    global song_history\n",
        "    start_collecting = False\n",
        "\n",
        "    for line in lines:\n",
        "        if \"Playlist:\" in line:\n",
        "            start_collecting = True\n",
        "            continue\n",
        "        if start_collecting and line.strip() and line[0].isdigit() and '.' in line:\n",
        "            line = line.replace(\"'\", \"\").replace('\"', \"\")\n",
        "            song_info = line.split(' - ')\n",
        "            if len(song_info) >= 2:\n",
        "                cleaned_lines.append(line.strip())\n",
        "        if len(cleaned_lines) == 10:\n",
        "            break\n",
        "    if len(cleaned_lines) != 10:\n",
        "        return \"Error: The generated playlist does not contain exactly 10 songs.\"\n",
        "    return \"\\n\".join(cleaned_lines)\n",
        "\n",
        "def query_rag_for_playlist(question):\n",
        "    filters = extract_filters(question)\n",
        "    genre_filter = filters.get(\"genre\", [])\n",
        "    emotion_filter = filters.get(\"emotion\", [])\n",
        "\n",
        "\n",
        "    if genre_filter:\n",
        "        genre_filter = genre_filter[0]\n",
        "    else:\n",
        "        genre_filter = None\n",
        "\n",
        "    context_documents = search_documents(question, genre_filter)\n",
        "    if context_documents:\n",
        "        context_excerpt = \"\\n\".join(context_documents[:1])\n",
        "    else:\n",
        "        context_excerpt = \"No relevant context found.\"\n",
        "\n",
        "\n",
        "    if genre_filter:\n",
        "        genre_text = f\"the genre '{genre_filter}'\"\n",
        "    else:\n",
        "        genre_text = \"the ambiance and emotions described\"\n",
        "\n",
        "    prompt = (\n",
        "        f\"{question}\\n\\n\"\n",
        "        f\"Provide exactly 10 unique songs that match this setting and reflect {genre_text}. \"\n",
        "        f\"Include both popular hits and hidden gems, with each song by a different artist. \"\n",
        "        f\"List them as 'Song Title - Artist'.\\n\\n\"\n",
        "        f\"Playlist:\\n1.\"\n",
        "    )\n",
        "\n",
        "    response = generate_response(prompt, retrieved_songs=context_documents, max_new_tokens=800)\n",
        "    cleaned_response = clean_response(response)\n",
        "    return cleaned_response\n",
        "\n",
        "def generate_youtube_links(response):\n",
        "    lines = response.split(\"\\n\")\n",
        "    youtube_links = []\n",
        "\n",
        "    for line in lines:\n",
        "        if ' - ' in line:\n",
        "            song_info = line.split(\" - \")\n",
        "            song_title = song_info[0].strip()\n",
        "            artist_info = song_info[1].split(\" (\")[0].strip()\n",
        "\n",
        "            query = f\"{song_title} {artist_info}\"\n",
        "            youtube_link = f\"https://www.youtube.com/results?search_query={query.replace(' ', '+')}\"\n",
        "            youtube_links.append(f\"[{song_title} - {artist_info}]({youtube_link})\")\n",
        "\n",
        "    return \"\\n\".join(youtube_links)\n",
        "\n",
        "def generate_playlist_explanation(response, genre_filter):\n",
        "    if genre_filter:\n",
        "        genre_text = f\"the genre '{genre_filter}'\"\n",
        "    else:\n",
        "        genre_text = \"the emotions and themes described in the prompt\"\n",
        "\n",
        "    prompt_for_explanation = (\n",
        "        f\"Based on the following playlist, explain why each song was chosen for {genre_text}. \"\n",
        "        f\"Discuss why each song is a good fit for the playlist.\\n\\n\"\n",
        "        f\"Playlist:\\n{response}\\n\\nExplanation:\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt_for_explanation, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=1000,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    explanation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return explanation.strip()\n",
        "\n",
        "def gradio_generate_playlist(question):\n",
        "    response = query_rag_for_playlist(question)\n",
        "    youtube_links = generate_youtube_links(response)\n",
        "\n",
        "    filters = extract_filters(question)\n",
        "    genre_filter = filters.get(\"genre\", [])[0] if filters.get(\"genre\") else None\n",
        "    explanation = generate_playlist_explanation(response, genre_filter)\n",
        "\n",
        "    return response, youtube_links, explanation\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_generate_playlist,\n",
        "    inputs=\"text\",\n",
        "    outputs=[\"text\", \"markdown\", \"text\"],\n",
        "    title=\"Abracadabra Playlist Generator\",\n",
        "    description=\"A LLM with a RAG of 500000 songs\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "qt_mPCM7FYMB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}